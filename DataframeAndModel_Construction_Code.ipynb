{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules to import\n",
    "\n",
    "!pip install --user nipy\n",
    "!pip install --user nilearn\n",
    "!pip install --user seaborn\n",
    "!pip install --user keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Imports\n",
    "\n",
    "import nilearn\n",
    "\n",
    "from nilearn.image import resample_to_img\n",
    "\n",
    "import pylab as plt\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nb\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import seaborn as sns #added\n",
    "sns.set(style=\"darkgrid\") #added\n",
    "\n",
    "from nilearn.image import mean_img #added\n",
    "from nilearn.plotting import plot_anat #added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal code parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local directory where the Data are mounted\n",
    "rootDirectory = \"/data/RMN/LUCA_PASQUINI\"\n",
    "\n",
    "# Local subdirectory where dataset is mounted\n",
    "dataDir = \"DATI_SEGMENTATI_SCALATI_media\"\n",
    "\n",
    "# Dataset dir\n",
    "datasetDir = f\"{rootDirectory}/{dataDir}\"\n",
    "\n",
    "#CSV fileroot \n",
    "fileName = f\"{rootDirectory}/{dataDir}/Array_Labels_Def.csv\"\n",
    "\n",
    "SUBJECT_NAME_REPEATED=[\"BIANCHI\",\"BOVE\",\"PROIETTI\"]\n",
    "\n",
    "#for i in range(len(SUBJECT_NAME_REPEATED)):\n",
    "#    f\"{SUBJECT_NAME_REPEATED[i]}\"\n",
    "#    print(f\"{SUBJECT_NAME_REPEATED[i]}\")\n",
    "\n",
    "PATIENT_REMOVED=['Pascal','Mitchell','Rufini','Farella','Array']\n",
    "\n",
    "SEQUENCE_1= \"ADC_registered\"\n",
    "SEQUENCE_2= \"ADC\"\n",
    "#T1_registered , T1\n",
    "#T2_registered , T2\n",
    "#FLAIR_registered , FLAIR\n",
    "#ADC_registered , ADC\n",
    "#rCBV_registered , rCBV\n",
    "#MPRAGEMDC\n",
    "MaskPath = \"SOLID\"\n",
    "#SOLID\n",
    "#NECROSI\n",
    "#T1ROI\n",
    "#T2ROI\n",
    "\n",
    "\n",
    "#reference dimensions\n",
    "dim1=192\n",
    "dim2=256\n",
    "dim3=144\n",
    "\n",
    "\n",
    "'''Model parameters'''\n",
    "\n",
    "#percentage of training test\n",
    "p=0.8\n",
    "\n",
    "# Specify shape of convolution kernel\n",
    "kernel_size = (3, 3)\n",
    "\n",
    "# Specify number of output categories\n",
    "n_classes = 2\n",
    "\n",
    "# Specify number of filters per layer\n",
    "filters = 16\n",
    "\n",
    "#added block\n",
    "nEpochs = 100  # Increase this value for better results (i.e., more training)\n",
    "\n",
    "batch_size = 16   # Increasing this value might speed up fitting\n",
    "\n",
    "activation='relu'\n",
    "\n",
    "activation_Dense='softmax'\n",
    "\n",
    "# optimizer\n",
    "learning_rate = 1e-5\n",
    "#adam = Adam(lr=learning_rate)\n",
    "#sgd = SGD(lr=learning_rate)\n",
    "\n",
    "loss='categorical_crossentropy'\n",
    "\n",
    "metrics=['accuracy']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survival Labels dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSV fileroot \n",
    "#fileName = \"/data/RMN/LUCA_PASQUINI/DATI_SEGMENTATI_SCALATI_media/Array_Labels_Def.csv\"\n",
    "\n",
    "#csv file\n",
    "df = pd.read_csv(fileName, sep=\";\", header=None)\n",
    "\n",
    "#Dataframe columns title\n",
    "df.columns = [\"Subject\", \"Survival\"]\n",
    "\n",
    "#Subject column as index\n",
    "df = df.set_index('Subject')\n",
    "\n",
    "#in order to check the entire dataframe of labels\n",
    "pd.set_option('display.max_rows', len(df))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NORMALIZE_NAME: the function takes the subject path basename and splits it according to the underscore\n",
    "#in order to take the first string and use it as index in dataframe.\n",
    "#If a string is repeated, the function adds the first letter of the second string after the underscore\n",
    "\n",
    "def normalize_name(subject_path, add_name):\n",
    "    #Components= []\n",
    "    subject = os.path.basename(subject_path)\n",
    "    subject = re.sub(r'^(DE|D|DI|LO|DEL)_', '', subject)\n",
    "    components =  subject.split(\"_\")\n",
    "    if add_name[0]==components[0] or add_name[1]==components[0] or add_name[2]==components[0] :\n",
    "            return components[0].title() + components[1][0].capitalize()\n",
    "    else:\n",
    "            return components[0].title()\n",
    "        \n",
    "    \n",
    "#GET_SUBJECT_METADATA:the function recives, as input, the subject path and the list of name repeated already known\n",
    "#the output are the path base name (SURNAME_NAME) and the normalized name\n",
    "#add_name needs to contain the list of name repeated\n",
    "\n",
    "\n",
    "def get_subject_metadata(subject_path, subjects_with_name=[]):\n",
    "    dirname = os.path.basename(subject_path)\n",
    "    return (dirname, normalize_name(subject_path, add_name=[name for name in subjects_with_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''' Get index positions of value in dataframe '''\n",
    "def getIndexes(dfObj, value):\n",
    "    listOfPos = list()\n",
    "    result = dfObj.isin([value]) # Get bool dataframe with True at positions where the given value exists\n",
    "    seriesObj = result.any() # Get list of columns that contains the value\n",
    "    columnNames = list(seriesObj[seriesObj == True].index)\n",
    "    for col in columnNames: # Iterate over list of columns and fetch the rows indexes where value exists\n",
    "        rows = list(result[col][result[col] == True].index)\n",
    "        for row in rows:\n",
    "            listOfPos.append((row, col))\n",
    "# Return a list of tuples indicating the positions of value in the dataframe\n",
    "    return listOfPos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe folders construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path and Subject columns\n",
    "Df_Subjects_dirs = pd.DataFrame()\n",
    "for subject_path in glob.glob(f\"{datasetDir}/*\"):\n",
    "    subjects_dirs=[get_subject_metadata(subject_path , subjects_with_name=[SUBJECT_NAME for SUBJECT_NAME in SUBJECT_NAME_REPEATED])]\n",
    "    print(subjects_dirs)\n",
    "    df_subject_dirs = pd.DataFrame(subjects_dirs,columns=[\"Path\", \"Subject\"])\n",
    "    Df_Subjects_dirs=pd.concat([Df_Subjects_dirs,df_subject_dirs],ignore_index=True)\n",
    "\n",
    "\n",
    "#in order to check the correct constucrion of \n",
    "pd.set_option('display.max_rows', len(Df_Subjects_dirs))\n",
    "print(Df_Subjects_dirs)\n",
    "\n",
    "#Subject as index\n",
    "Df_Subjects_dirs = Df_Subjects_dirs.set_index('Subject')\n",
    "pd.set_option('display.max_rows', len(Df_Subjects_dirs))\n",
    "\n",
    "#in order to check the correct constucrion of Df_Subjects_dirs\n",
    "print(Df_Subjects_dirs)\n",
    "\n",
    "#Unnecessary strings removal with \"drop\" function\n",
    "x=Df_Subjects_dirs\n",
    "x.drop(index='Array', columns='Path')\n",
    "# Delete rows with index label a & b    \n",
    "modX= x.drop([PATIENT for PATIENT in PATIENT_REMOVED])\n",
    "#modX[\"Path\"]\n",
    "modX = pd.DataFrame(modX)\n",
    "\n",
    "#in order to check the correct construction of the dataframe\n",
    "pd.set_option('display.max_rows', len(modX))\n",
    "print(modX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join function between Path and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = modX.join(df, on='Subject')\n",
    "\n",
    "#in order to check if all the dataframe is construced in the right way\n",
    "pd.set_option('display.max_rows', len(result))\n",
    "result   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAN removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it takes the indexes to which the NaN corresponds\n",
    "NAN_index=result['Survival'].index[result['Survival'].apply(np.isnan)]\n",
    "\n",
    "#it takes the number of the corresponding row as int\n",
    "df_index=result.index.values.tolist()\n",
    "int_index=[df_index.index(i) for i in NAN_index]\n",
    "#int_index\n",
    "\n",
    "#than it is possible to obtain the corresponding survival label of the original array, df in this case\n",
    "label=[df.iloc[x]['Survival'] for x in int_index]\n",
    "label\n",
    "\n",
    "#iteration to replace the NaNs\n",
    "for l in label:\n",
    "    result['Survival'].fillna(l,inplace=True)\n",
    "    \n",
    "#result is the final Dataframe with \"Subject\" as index and the columns \"Path\" and \"Survival\"\n",
    "pd.set_option('display.max_rows', len(result))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "result = pickle.load( open( \"DataFrame.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data loading\n",
    "listOfElems=[]  #array that need to obtain the effective subjects with the sequence that we want to analyse \n",
    "Dim = []  #array that need to contain the dimension of each image in order to check the most frequent or the minimum one\n",
    "Data = [] #array that contains information of the image after the extraction of data from the nibabel format\n",
    "IMG=[] #array that contains the \"file.nii.gz\" information thanks to the nibabel module \n",
    "for Path in result[\"Path\"]: #here starts the iteration on all the paths written in the column \"Path\" in result dataframe\n",
    "    #print(Path)\n",
    "    if os.path.isfile(f\"{datasetDir}/{Path}/{SEQUENCE_1}.nii\"): #I need just the Paths that contain a certain sequence\n",
    "\n",
    "        IMG_reg = nb.load(f\"{datasetDir}/{Path}/{SEQUENCE_1}.nii\") #nobabel module that allow the loading of nifty file\n",
    "        DATA= np.asarray(IMG_reg.dataobj) #get_data takes the information about scale of gray\n",
    "        a = [DATA.shape]\n",
    "        Dim.append(a) #allows the array construction\n",
    "        Data.append(DATA)  #allows the array construction\n",
    "        IMG.append(IMG_reg)  #allows the array construction\n",
    "        \n",
    "\n",
    "        IMG_roi = nb.load(f\"{datasetDir}/{Path}/ROI/{MaskPath}.nii\") #that's the file of the mask that limits information only on a certain region of the tumor\n",
    "        ROI_DATA=np.asarray(IMG_roi.dataobj)\n",
    "        b=[ROI_DATA.shape]\n",
    "        Dim.append(b)\n",
    "        Data.append(ROI_DATA)\n",
    "        IMG.append(IMG_roi)\n",
    "        \n",
    "        path=[f\"{Path}\"]\n",
    "        listOfElems.append(path) #allows the array construction\n",
    "        \n",
    "    else: #anyway there are some patient with the sequence with different name but with the same information, so I can include them with the \"else\"\n",
    "        if os.path.isfile(f\"{datasetDir}/{Path}/{SEQUENCE_2}.nii\"):\n",
    "            IMG_reg = nb.load(f\"{datasetDir}/{Path}/{SEQUENCE_2}.nii\")\n",
    "            DATA= np.asarray(IMG_reg.dataobj)\n",
    "            a = [DATA.shape]\n",
    "            Dim.append(a)\n",
    "            Data.append(DATA)\n",
    "            IMG.append(IMG_reg)\n",
    "            \n",
    "            IMG_roi = nb.load(f\"{datasetDir}/{Path}/ROI/{MaskPath}.nii\")\n",
    "            ROI_DATA=np.asarray(IMG_roi.dataobj)\n",
    "            b=[ROI_DATA.shape]\n",
    "            Dim.append(b)\n",
    "            Data.append(ROI_DATA)\n",
    "            IMG.append(IMG_roi)\n",
    "            \n",
    "            path=[f\"{Path}\"]\n",
    "            listOfElems.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "IMG_reg = nb.load(f\"{datasetDir}/BIANCHI_ORAZIO/{SEQUENCE_1}.nii\") #nibabel module that allow the loading of nifty file\n",
    "DATA= np.asarray(IMG_reg.dataobj)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listOfElems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data[20][39][100][30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alessandrini\n",
      "Angeloni\n",
      "Assanto\n",
      "Bagnoli\n",
      "Barontini\n",
      "Battista\n",
      "Bergnach\n",
      "Bertuzzi\n",
      "Bevilacqua\n",
      "BianchiG\n",
      "Boezi\n",
      "Cacace\n",
      "Caldaroni\n",
      "Camacci\n",
      "Camplese\n",
      "Capezzone\n",
      "Carzedda\n",
      "Colafrancesco\n",
      "Colamartini\n",
      "Colazzo\n",
      "Coletta\n",
      "Cosimi\n",
      "Crescenzi\n",
      "Darida\n",
      "BoveP\n",
      "Santis\n",
      "Carlatonio\n",
      "Lorenzo\n",
      "Maso\n",
      "Massa\n",
      "Dobrisan\n",
      "Droghei\n",
      "Angeli\n",
      "Angelo\n",
      "Fabiani\n",
      "Federico\n",
      "Ferrazza\n",
      "Filipponi\n",
      "Florio\n",
      "Fratini\n",
      "Gattamorta\n",
      "Geggi\n",
      "Gennari\n",
      "Gianfelici\n",
      "Gioia\n",
      "Giordano\n",
      "Inciti\n",
      "Ionta\n",
      "Isoni\n",
      "Labella\n",
      "Landone\n",
      "Lioce\n",
      "Longo\n",
      "Bello\n",
      "Lupi\n",
      "Lupo\n",
      "Maiolini\n",
      "Maragno\n",
      "Marcolini\n",
      "Mariani\n",
      "Marocchi\n",
      "Martella\n",
      "Martinez\n",
      "Masci\n",
      "Medici\n",
      "Micheli\n",
      "Monacelli\n",
      "Moscardini\n",
      "Musat\n",
      "Nerone\n",
      "Pagannone\n",
      "Pagliaroli\n",
      "Pagnotta\n",
      "Palma\n",
      "Palmieri\n",
      "Panetti\n",
      "Passari\n",
      "Pieri\n",
      "Pierini\n",
      "Pineda\n",
      "Pistoia\n",
      "Podagrosi\n",
      "Podda\n",
      "Principi\n",
      "ProiettiG\n",
      "ProiettiM\n",
      "Quattrociocchi\n",
      "Re\n",
      "Ricci\n",
      "Romito\n",
      "Rosari\n",
      "Ruscito\n",
      "Rusnac\n",
      "Russo\n",
      "Sala\n",
      "Saltarelli\n",
      "Santini\n",
      "Soloviy\n",
      "Stan\n",
      "Stefanini\n",
      "Sterpa\n",
      "Sykula\n",
      "Tavolucci\n",
      "Tempestini\n",
      "Temporin\n",
      "Teofili\n",
      "Testa\n",
      "Tiberi\n",
      "Tomao\n",
      "Tomeo\n",
      "Veronesi\n",
      "Vitulano\n",
      "Zangari\n",
      "Zeppa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Labels Array Construction'''\n",
    "\n",
    "#the following iteration allows the extraction of indexes corresponding to the paths selected by the preavious iterations\n",
    "T1_Subject=[]\n",
    "for i in range(len(listOfElems)):\n",
    "    Pos=getIndexes(result, listOfElems[i][0])\n",
    "    print(Pos[0][0])\n",
    "    T1_Subject.append(Pos[0][0])  #the T1_Subject array contains these information\n",
    "\n",
    "#the following iteration takes the corresponding Survival information on the result Dataframe built before    \n",
    "T1_Subject_array=np.asarray(T1_Subject)\n",
    "\n",
    "T1_Labels=[]\n",
    "for i in range(len(T1_Subject_array)):\n",
    "    lab = result.loc[T1_Subject_array[i],\"Survival\"]\n",
    "    T1_Labels.append(int(lab)) #creates the list that contains these information\n",
    "\n",
    "T1_Labels=np.asarray(T1_Labels) #that's the relative array\n",
    "T1_Labels.shape\n",
    "\n",
    "#the following iteration allows the construction of the final labels array with doubled information of each element of T1_Labels array\n",
    "Label_Def=[]\n",
    "for x in range(len(T1_Labels)):\n",
    "    label_Def=[[T1_Labels[x]]*2]\n",
    "    Label_Def.append(label_Def)\n",
    "    \n",
    "Label_Def=np.asarray(Label_Def)\n",
    "Label_Def=np.ravel(Label_Def)\n",
    "Label_Def #that's the final label array that can be used for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 68,\n",
       " 69,\n",
       " 74,\n",
       " 75,\n",
       " 84,\n",
       " 85,\n",
       " 88,\n",
       " 89,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 110,\n",
       " 111,\n",
       " 114,\n",
       " 115,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 134,\n",
       " 135,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 150,\n",
       " 151,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 226,\n",
       " 227]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Working on dimensions'''\n",
    "\n",
    "#in order to work on dimensions it's necessary the array construction (as predicted in previous blocks)\n",
    "Dim=np.asarray(Dim)   \n",
    "Data=np.asarray(Data)\n",
    "IMG=np.asarray(IMG)\n",
    "\n",
    "#in order to know the minimum dimensions\n",
    "Min_value=np.amin(Dim, axis=1)\n",
    "Min_value\n",
    "Min=np.amin(Min_value, axis=0)\n",
    "Min_value.shape[0]\n",
    "\n",
    "not_in_index = [k for k in range(Min_value.shape[0]) if not np.all(Min_value[k] == (dim1, dim2, dim3))] #that's the\n",
    "#construction of an array that contains the position not corresponding to the dimension researched [(192,256,144)\n",
    "#in this case]\n",
    "\n",
    "pos_1=np.where(Min_value[:,0]==dim1) #position with first dimension equal to 192\n",
    "pos_2=np.where(Min_value[:,1]==dim2) #position with first dimension equal to 256\n",
    "pos_3=np.where(Min_value[:,2]==dim3) #position with first dimension equal to 144\n",
    "eq=np.intersect1d(pos_1,pos_2)  #that command in order to find the intersection between the pos_1 and pos_2\n",
    "index_IMG=np.intersect1d(eq,pos_3) #intersection that gives the complememntary information of not_in_index\n",
    "\n",
    "#Here is given a random position that corresponds to the dimension request\n",
    "def_index=random.choice(index_IMG)\n",
    "print(def_index)\n",
    "\n",
    "\n",
    "not_in_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''RESAMPLE BLOCK'''\n",
    "\n",
    "#The resample function is executed only on images without the dimension request, respect to a random image with dimension (192,256,144)\n",
    "for i in not_in_index:\n",
    "    Res=nilearn.image.resample_to_img(IMG[i], IMG[def_index],interpolation='nearest')\n",
    "    IMG[i]=Res\n",
    "    Data[i]=np.asarray(IMG[i].dataobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump( Data[:], open( \"ADC_Solid_Dataset.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('rCBV_Solid', Data)\n",
    "\n",
    "#Data=np.load('rCBV_Solid.npy',allow_pickle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_matrix=np.array(Data[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 192, 256, 144)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Reshaping of Input Matrix'''\n",
    "\n",
    "Input_matrix=np.empty((len(Data),dim1,dim2,dim3)) #in order to generate an empty array with a fixed shape\n",
    "\n",
    "for i in not_in_index:\n",
    "\n",
    "    Input_matrix[i,:,:,:]=np.array(Data[i])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in index_IMG:\n",
    "\n",
    "    Input_matrix[i,:,:,:]=np.array(Data[i])\n",
    "    \n",
    "    \n",
    "#in order to check the correct construction    \n",
    "Input_matrix.shape\n",
    "\n",
    "#import pickle\n",
    "#pickle.dump( Input_matrix, open( \"Input_matrix.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 192, 256, 144, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "data = Input_matrix[...,None]\n",
    "data.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''Modules needed'''\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=Label_Def\n",
    "from keras.utils import to_categorical\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''## Create list of indices and shuffle them\n",
    "N = Input_matrix.shape[0]\n",
    "indices = np.arange(N)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "#  Cut the dataset at 80% to create the training and test set\n",
    "N_80p = int(p * N)\n",
    "indices_train = indices[:N_80p]\n",
    "indices_test = indices[N_80p:]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train = Input_matrix[indices_train, ...]\n",
    "X_test = Input_matrix[indices_test, ...]\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "labels=Label_Def\n",
    "\n",
    "#Outcome variable block added\n",
    "y_train = labels[indices_train] == 0\n",
    "y_test = labels[indices_test] == 1\n",
    "\n",
    "from keras.utils import to_categorical #Convert a class vector (integer) into binary class matrix\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "y_train'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 256, 144)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Parameters setting'''\n",
    "\n",
    "# Get shape of input data\n",
    "data_shape = Data[0].shape\n",
    "\n",
    "data_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 190, 254, 16)      20752     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 190, 254, 16)      64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 95, 127, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 93, 125, 32)       4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 93, 125, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 46, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 44, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 44, 60, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 22, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 42240)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               10813696  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 10,990,642\n",
      "Trainable params: 10,990,418\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model block added\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters, kernel_size, activation='relu', input_shape=data_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(filters * 2, kernel_size, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(filters * 4, kernel_size, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# optimizer\n",
    "learning_rate = 1e-5\n",
    "adam = Adam(lr=learning_rate)\n",
    "sgd = SGD(lr=learning_rate)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=adam, # swap out for sgd \n",
    "              metrics=['accuracy','binary_crossentropy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 190, 254, 16)      20752     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 190, 254, 16)      64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 95, 127, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 93, 125, 32)       4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 93, 125, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 46, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 44, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 44, 60, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 22, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 42240)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               10813696  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 10,990,642\n",
      "Trainable params: 10,990,418\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model block added\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters, kernel_size, activation='relu', input_shape=data_shape,kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(filters * 2, kernel_size, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(filters * 4, kernel_size, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(n_classes, activation='softmax',kernel_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "# optimizer\n",
    "learning_rate = 1e-5\n",
    "adam = Adam(lr=learning_rate)\n",
    "sgd = SGD(lr=learning_rate)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=adam, # swap out for sgd \n",
    "              metrics=['accuracy','binary_crossentropy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "base_model = tf.keras.applications.VGG19(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(128, 128, 3)\n",
    ")\n",
    "base_model.trainable = False\n",
    "model = base_model.output\n",
    "model = tf.keras.layers.GlobalAveragePooling2D()(model)\n",
    "model = tf.keras.layers.Dense(units=512, activation='relu')(model)\n",
    "model = tf.keras.layers.Dropout(0.7)(model)\n",
    "predictions = tf.keras.layers.Dense(units=2, activation='softmax')(model)\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 182 samples, validate on 46 samples\n",
      "Epoch 1/500\n",
      "182/182 [==============================] - 26s 142ms/step - loss: 1.9880 - accuracy: 0.5220 - binary_crossentropy: 1.0387 - val_loss: 1.7530 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.8038\n",
      "Epoch 2/500\n",
      "182/182 [==============================] - 19s 102ms/step - loss: 1.9917 - accuracy: 0.5220 - binary_crossentropy: 1.0425 - val_loss: 1.6942 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7451\n",
      "Epoch 3/500\n",
      "182/182 [==============================] - 19s 103ms/step - loss: 1.9408 - accuracy: 0.5275 - binary_crossentropy: 0.9916 - val_loss: 1.6713 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7223\n",
      "Epoch 4/500\n",
      "182/182 [==============================] - 18s 100ms/step - loss: 1.9497 - accuracy: 0.5220 - binary_crossentropy: 1.0006 - val_loss: 1.6891 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7401\n",
      "Epoch 5/500\n",
      "182/182 [==============================] - 18s 99ms/step - loss: 1.8588 - accuracy: 0.5549 - binary_crossentropy: 0.9099 - val_loss: 1.6587 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7098\n",
      "Epoch 6/500\n",
      "182/182 [==============================] - 18s 102ms/step - loss: 1.7098 - accuracy: 0.6429 - binary_crossentropy: 0.7609 - val_loss: 1.6425 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.6936\n",
      "Epoch 7/500\n",
      "182/182 [==============================] - 19s 104ms/step - loss: 1.7206 - accuracy: 0.6099 - binary_crossentropy: 0.7718 - val_loss: 1.6429 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.6941\n",
      "Epoch 8/500\n",
      "182/182 [==============================] - 18s 98ms/step - loss: 1.6515 - accuracy: 0.6429 - binary_crossentropy: 0.7027 - val_loss: 1.6369 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.6882\n",
      "Epoch 9/500\n",
      "182/182 [==============================] - 18s 98ms/step - loss: 1.7209 - accuracy: 0.5495 - binary_crossentropy: 0.7722 - val_loss: 1.6389 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.6902\n",
      "Epoch 10/500\n",
      "182/182 [==============================] - 18s 100ms/step - loss: 1.6257 - accuracy: 0.5604 - binary_crossentropy: 0.6770 - val_loss: 1.6329 - val_accuracy: 0.6087 - val_binary_crossentropy: 0.6843\n",
      "Epoch 11/500\n",
      "182/182 [==============================] - 18s 99ms/step - loss: 1.6532 - accuracy: 0.6374 - binary_crossentropy: 0.7047 - val_loss: 1.6262 - val_accuracy: 0.6087 - val_binary_crossentropy: 0.6776\n",
      "Epoch 12/500\n",
      "182/182 [==============================] - 18s 99ms/step - loss: 1.5066 - accuracy: 0.6923 - binary_crossentropy: 0.5581 - val_loss: 1.6220 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.6735\n",
      "Epoch 13/500\n",
      "182/182 [==============================] - 18s 98ms/step - loss: 1.5481 - accuracy: 0.6758 - binary_crossentropy: 0.5997 - val_loss: 1.6228 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.6745\n",
      "Epoch 14/500\n",
      "182/182 [==============================] - 18s 99ms/step - loss: 1.5791 - accuracy: 0.6209 - binary_crossentropy: 0.6308 - val_loss: 1.6285 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.6802\n",
      "Epoch 15/500\n",
      "182/182 [==============================] - 19s 104ms/step - loss: 1.6803 - accuracy: 0.5989 - binary_crossentropy: 0.7320 - val_loss: 1.6315 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.6833\n",
      "Epoch 16/500\n",
      "182/182 [==============================] - 18s 99ms/step - loss: 1.4841 - accuracy: 0.7143 - binary_crossentropy: 0.5359 - val_loss: 1.6455 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.6973\n",
      "Epoch 17/500\n",
      "182/182 [==============================] - 18s 98ms/step - loss: 1.5232 - accuracy: 0.6978 - binary_crossentropy: 0.5751 - val_loss: 1.6430 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.6949\n",
      "Epoch 18/500\n",
      "182/182 [==============================] - 19s 103ms/step - loss: 1.4458 - accuracy: 0.6978 - binary_crossentropy: 0.4977 - val_loss: 1.6458 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.6978\n",
      "Epoch 19/500\n",
      "182/182 [==============================] - 18s 100ms/step - loss: 1.4792 - accuracy: 0.6813 - binary_crossentropy: 0.5312 - val_loss: 1.6407 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.6927\n",
      "Epoch 20/500\n",
      "182/182 [==============================] - 18s 100ms/step - loss: 1.4874 - accuracy: 0.7143 - binary_crossentropy: 0.5395 - val_loss: 1.6330 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.6851\n",
      "Epoch 21/500\n",
      "182/182 [==============================] - 19s 105ms/step - loss: 1.5485 - accuracy: 0.6319 - binary_crossentropy: 0.6007 - val_loss: 1.6334 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.6856\n",
      "Epoch 22/500\n",
      "182/182 [==============================] - 18s 100ms/step - loss: 1.5644 - accuracy: 0.6538 - binary_crossentropy: 0.6166 - val_loss: 1.6387 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.6910\n",
      "Epoch 23/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.4611 - accuracy: 0.6978 - binary_crossentropy: 0.5134 - val_loss: 1.6565 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.7088\n",
      "Epoch 24/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.4427 - accuracy: 0.7363 - binary_crossentropy: 0.4951 - val_loss: 1.6542 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7067\n",
      "Epoch 25/500\n",
      "182/182 [==============================] - 17s 96ms/step - loss: 1.5045 - accuracy: 0.6593 - binary_crossentropy: 0.5570 - val_loss: 1.6480 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.7005\n",
      "Epoch 26/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.4179 - accuracy: 0.7363 - binary_crossentropy: 0.4705 - val_loss: 1.6521 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.7047\n",
      "Epoch 27/500\n",
      "182/182 [==============================] - 17s 96ms/step - loss: 1.4788 - accuracy: 0.6374 - binary_crossentropy: 0.5314 - val_loss: 1.6617 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.7143\n",
      "Epoch 28/500\n",
      "182/182 [==============================] - 18s 97ms/step - loss: 1.4510 - accuracy: 0.7033 - binary_crossentropy: 0.5037 - val_loss: 1.6609 - val_accuracy: 0.5870 - val_binary_crossentropy: 0.7136\n",
      "Epoch 29/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.4881 - accuracy: 0.6593 - binary_crossentropy: 0.5409 - val_loss: 1.6525 - val_accuracy: 0.5870 - val_binary_crossentropy: 0.7053\n",
      "Epoch 30/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.4828 - accuracy: 0.6648 - binary_crossentropy: 0.5357 - val_loss: 1.6556 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.7084\n",
      "Epoch 31/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.4097 - accuracy: 0.7363 - binary_crossentropy: 0.4626 - val_loss: 1.6548 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.7078\n",
      "Epoch 32/500\n",
      "182/182 [==============================] - 18s 98ms/step - loss: 1.4166 - accuracy: 0.7473 - binary_crossentropy: 0.4696 - val_loss: 1.6645 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.7175\n",
      "Epoch 33/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.4155 - accuracy: 0.6813 - binary_crossentropy: 0.4686 - val_loss: 1.6630 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7161\n",
      "Epoch 34/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3594 - accuracy: 0.7802 - binary_crossentropy: 0.4126 - val_loss: 1.6662 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7194\n",
      "Epoch 35/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.4467 - accuracy: 0.6923 - binary_crossentropy: 0.4999 - val_loss: 1.6624 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.7157\n",
      "Epoch 36/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3989 - accuracy: 0.7088 - binary_crossentropy: 0.4522 - val_loss: 1.6589 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.7123\n",
      "Epoch 37/500\n",
      "182/182 [==============================] - 18s 98ms/step - loss: 1.4190 - accuracy: 0.7143 - binary_crossentropy: 0.4724 - val_loss: 1.6658 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.7193\n",
      "Epoch 38/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3733 - accuracy: 0.7527 - binary_crossentropy: 0.4268 - val_loss: 1.6713 - val_accuracy: 0.4783 - val_binary_crossentropy: 0.7249\n",
      "Epoch 39/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3929 - accuracy: 0.7033 - binary_crossentropy: 0.4465 - val_loss: 1.6755 - val_accuracy: 0.4783 - val_binary_crossentropy: 0.7291\n",
      "Epoch 40/500\n",
      "182/182 [==============================] - 17s 96ms/step - loss: 1.3831 - accuracy: 0.6923 - binary_crossentropy: 0.4368 - val_loss: 1.6661 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.7198\n",
      "Epoch 41/500\n",
      "182/182 [==============================] - 17s 96ms/step - loss: 1.3635 - accuracy: 0.7363 - binary_crossentropy: 0.4172 - val_loss: 1.6683 - val_accuracy: 0.4783 - val_binary_crossentropy: 0.7222\n",
      "Epoch 42/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3913 - accuracy: 0.6868 - binary_crossentropy: 0.4452 - val_loss: 1.6733 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.7272\n",
      "Epoch 43/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3755 - accuracy: 0.7253 - binary_crossentropy: 0.4294 - val_loss: 1.6799 - val_accuracy: 0.4783 - val_binary_crossentropy: 0.7339\n",
      "Epoch 44/500\n",
      "182/182 [==============================] - 17s 96ms/step - loss: 1.3766 - accuracy: 0.7418 - binary_crossentropy: 0.4307 - val_loss: 1.6780 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.7321\n",
      "Epoch 45/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3636 - accuracy: 0.6978 - binary_crossentropy: 0.4177 - val_loss: 1.6876 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.7418\n",
      "Epoch 46/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.4258 - accuracy: 0.6593 - binary_crossentropy: 0.4800 - val_loss: 1.6750 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.7292\n",
      "Epoch 47/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3690 - accuracy: 0.7033 - binary_crossentropy: 0.4233 - val_loss: 1.6710 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7253\n",
      "Epoch 48/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.4084 - accuracy: 0.6703 - binary_crossentropy: 0.4628 - val_loss: 1.7078 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.7622\n",
      "Epoch 49/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3741 - accuracy: 0.6923 - binary_crossentropy: 0.4286 - val_loss: 1.7101 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7646\n",
      "Epoch 50/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3808 - accuracy: 0.7363 - binary_crossentropy: 0.4354 - val_loss: 1.7000 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.7547\n",
      "Epoch 51/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3980 - accuracy: 0.7033 - binary_crossentropy: 0.4527 - val_loss: 1.6792 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.7339\n",
      "Epoch 52/500\n",
      "182/182 [==============================] - 18s 98ms/step - loss: 1.3929 - accuracy: 0.6813 - binary_crossentropy: 0.4477 - val_loss: 1.6632 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7181\n",
      "Epoch 53/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.4067 - accuracy: 0.7692 - binary_crossentropy: 0.4616 - val_loss: 1.6721 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.7271\n",
      "Epoch 54/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3694 - accuracy: 0.6978 - binary_crossentropy: 0.4243 - val_loss: 1.6821 - val_accuracy: 0.5870 - val_binary_crossentropy: 0.7371\n",
      "Epoch 55/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3282 - accuracy: 0.7857 - binary_crossentropy: 0.3833 - val_loss: 1.6822 - val_accuracy: 0.5870 - val_binary_crossentropy: 0.7373\n",
      "Epoch 56/500\n",
      "182/182 [==============================] - 18s 98ms/step - loss: 1.3903 - accuracy: 0.6868 - binary_crossentropy: 0.4455 - val_loss: 1.6807 - val_accuracy: 0.5870 - val_binary_crossentropy: 0.7359\n",
      "Epoch 57/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3549 - accuracy: 0.7308 - binary_crossentropy: 0.4102 - val_loss: 1.6864 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7417\n",
      "Epoch 58/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.4006 - accuracy: 0.6648 - binary_crossentropy: 0.4560 - val_loss: 1.6942 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.7497\n",
      "Epoch 59/500\n",
      "182/182 [==============================] - 17s 96ms/step - loss: 1.3810 - accuracy: 0.6978 - binary_crossentropy: 0.4365 - val_loss: 1.6912 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.7467\n",
      "Epoch 60/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3256 - accuracy: 0.7857 - binary_crossentropy: 0.3812 - val_loss: 1.6952 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7509\n",
      "Epoch 61/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3531 - accuracy: 0.7418 - binary_crossentropy: 0.4088 - val_loss: 1.6941 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7498\n",
      "Epoch 62/500\n",
      "182/182 [==============================] - 17s 96ms/step - loss: 1.3892 - accuracy: 0.7363 - binary_crossentropy: 0.4450 - val_loss: 1.6813 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.7372\n",
      "Epoch 63/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3485 - accuracy: 0.7253 - binary_crossentropy: 0.4045 - val_loss: 1.6877 - val_accuracy: 0.4783 - val_binary_crossentropy: 0.7437\n",
      "Epoch 64/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3795 - accuracy: 0.6703 - binary_crossentropy: 0.4355 - val_loss: 1.6940 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.7500\n",
      "Epoch 65/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3652 - accuracy: 0.7308 - binary_crossentropy: 0.4213 - val_loss: 1.7014 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7576\n",
      "Epoch 66/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3437 - accuracy: 0.7473 - binary_crossentropy: 0.4000 - val_loss: 1.7165 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.7728\n",
      "Epoch 67/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3601 - accuracy: 0.7088 - binary_crossentropy: 0.4165 - val_loss: 1.7442 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.8006\n",
      "Epoch 68/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3487 - accuracy: 0.7418 - binary_crossentropy: 0.4051 - val_loss: 1.7421 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.7986\n",
      "Epoch 69/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3374 - accuracy: 0.7253 - binary_crossentropy: 0.3940 - val_loss: 1.7250 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7816\n",
      "Epoch 70/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3656 - accuracy: 0.6978 - binary_crossentropy: 0.4223 - val_loss: 1.7139 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.7706\n",
      "Epoch 71/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3371 - accuracy: 0.7198 - binary_crossentropy: 0.3939 - val_loss: 1.7238 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.7806\n",
      "Epoch 72/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3294 - accuracy: 0.7582 - binary_crossentropy: 0.3863 - val_loss: 1.7382 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.7951\n",
      "Epoch 73/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3278 - accuracy: 0.7637 - binary_crossentropy: 0.3848 - val_loss: 1.7425 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.7996\n",
      "Epoch 74/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3417 - accuracy: 0.7198 - binary_crossentropy: 0.3988 - val_loss: 1.7532 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.8104\n",
      "Epoch 75/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3641 - accuracy: 0.6868 - binary_crossentropy: 0.4213 - val_loss: 1.7523 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.8096\n",
      "Epoch 76/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3368 - accuracy: 0.7363 - binary_crossentropy: 0.3942 - val_loss: 1.7541 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.8115\n",
      "Epoch 77/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3344 - accuracy: 0.6868 - binary_crossentropy: 0.3919 - val_loss: 1.7556 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.8131\n",
      "Epoch 78/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3525 - accuracy: 0.7363 - binary_crossentropy: 0.4101 - val_loss: 1.7392 - val_accuracy: 0.5870 - val_binary_crossentropy: 0.7969\n",
      "Epoch 79/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3538 - accuracy: 0.7582 - binary_crossentropy: 0.4115 - val_loss: 1.7873 - val_accuracy: 0.5870 - val_binary_crossentropy: 0.8451\n",
      "Epoch 80/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3543 - accuracy: 0.7253 - binary_crossentropy: 0.4122 - val_loss: 1.7662 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.8241\n",
      "Epoch 81/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3381 - accuracy: 0.7088 - binary_crossentropy: 0.3960 - val_loss: 1.7681 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.8261\n",
      "Epoch 82/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3129 - accuracy: 0.7912 - binary_crossentropy: 0.3709 - val_loss: 1.7604 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.8185\n",
      "Epoch 83/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3437 - accuracy: 0.7363 - binary_crossentropy: 0.4019 - val_loss: 1.7387 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.7969\n",
      "Epoch 84/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3351 - accuracy: 0.7033 - binary_crossentropy: 0.3934 - val_loss: 1.7389 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.7973\n",
      "Epoch 85/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3488 - accuracy: 0.7198 - binary_crossentropy: 0.4072 - val_loss: 1.7215 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.7800\n",
      "Epoch 86/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3452 - accuracy: 0.7088 - binary_crossentropy: 0.4037 - val_loss: 1.7155 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.7741\n",
      "Epoch 87/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3336 - accuracy: 0.7692 - binary_crossentropy: 0.3923 - val_loss: 1.7147 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.7734\n",
      "Epoch 88/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3539 - accuracy: 0.7143 - binary_crossentropy: 0.4127 - val_loss: 1.7319 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.7908\n",
      "Epoch 89/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3285 - accuracy: 0.7363 - binary_crossentropy: 0.3874 - val_loss: 1.7438 - val_accuracy: 0.6087 - val_binary_crossentropy: 0.8028\n",
      "Epoch 90/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3559 - accuracy: 0.6703 - binary_crossentropy: 0.4149 - val_loss: 1.7233 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.7824\n",
      "Epoch 91/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3300 - accuracy: 0.7692 - binary_crossentropy: 0.3892 - val_loss: 1.7128 - val_accuracy: 0.5870 - val_binary_crossentropy: 0.7721\n",
      "Epoch 92/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3501 - accuracy: 0.7198 - binary_crossentropy: 0.4094 - val_loss: 1.7067 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.7661\n",
      "Epoch 93/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3171 - accuracy: 0.7692 - binary_crossentropy: 0.3765 - val_loss: 1.7079 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7673\n",
      "Epoch 94/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3545 - accuracy: 0.7473 - binary_crossentropy: 0.4140 - val_loss: 1.7127 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7723\n",
      "Epoch 95/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3268 - accuracy: 0.7692 - binary_crossentropy: 0.3865 - val_loss: 1.7037 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.7634\n",
      "Epoch 96/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3388 - accuracy: 0.7363 - binary_crossentropy: 0.3986 - val_loss: 1.7043 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7642\n",
      "Epoch 97/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3241 - accuracy: 0.7418 - binary_crossentropy: 0.3841 - val_loss: 1.7701 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.8301\n",
      "Epoch 98/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3348 - accuracy: 0.7198 - binary_crossentropy: 0.3948 - val_loss: 1.7871 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.8472\n",
      "Epoch 99/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3254 - accuracy: 0.7527 - binary_crossentropy: 0.3856 - val_loss: 1.7785 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.8388\n",
      "Epoch 100/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3325 - accuracy: 0.7308 - binary_crossentropy: 0.3928 - val_loss: 1.8450 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.9053\n",
      "Epoch 101/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3224 - accuracy: 0.7418 - binary_crossentropy: 0.3829 - val_loss: 1.8341 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.8946\n",
      "Epoch 102/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3141 - accuracy: 0.7692 - binary_crossentropy: 0.3746 - val_loss: 1.7915 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.8522\n",
      "Epoch 103/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3530 - accuracy: 0.6978 - binary_crossentropy: 0.4137 - val_loss: 1.7565 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.8172\n",
      "Epoch 104/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3351 - accuracy: 0.7418 - binary_crossentropy: 0.3959 - val_loss: 1.7523 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.8132\n",
      "Epoch 105/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3334 - accuracy: 0.7033 - binary_crossentropy: 0.3943 - val_loss: 1.7471 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.8081\n",
      "Epoch 106/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3269 - accuracy: 0.7582 - binary_crossentropy: 0.3880 - val_loss: 1.7378 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7990\n",
      "Epoch 107/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3328 - accuracy: 0.7143 - binary_crossentropy: 0.3941 - val_loss: 1.7305 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7918\n",
      "Epoch 108/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3298 - accuracy: 0.7253 - binary_crossentropy: 0.3912 - val_loss: 1.7302 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.7917\n",
      "Epoch 109/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3238 - accuracy: 0.7198 - binary_crossentropy: 0.3853 - val_loss: 1.7513 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.8129\n",
      "Epoch 110/500\n",
      "182/182 [==============================] - 17s 96ms/step - loss: 1.3370 - accuracy: 0.7253 - binary_crossentropy: 0.3987 - val_loss: 1.7345 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7962\n",
      "Epoch 111/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3158 - accuracy: 0.7033 - binary_crossentropy: 0.3776 - val_loss: 1.7254 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7873\n",
      "Epoch 112/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3222 - accuracy: 0.7198 - binary_crossentropy: 0.3841 - val_loss: 1.7328 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7948\n",
      "Epoch 113/500\n",
      "182/182 [==============================] - 17s 96ms/step - loss: 1.3475 - accuracy: 0.7308 - binary_crossentropy: 0.4096 - val_loss: 1.7286 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.7908\n",
      "Epoch 114/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3096 - accuracy: 0.8077 - binary_crossentropy: 0.3718 - val_loss: 1.7118 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.7741\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3278 - accuracy: 0.7088 - binary_crossentropy: 0.3902 - val_loss: 1.6978 - val_accuracy: 0.5870 - val_binary_crossentropy: 0.7603\n",
      "Epoch 116/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3331 - accuracy: 0.7143 - binary_crossentropy: 0.3956 - val_loss: 1.7006 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7632\n",
      "Epoch 117/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3262 - accuracy: 0.6813 - binary_crossentropy: 0.3889 - val_loss: 1.7063 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7691\n",
      "Epoch 118/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3471 - accuracy: 0.7308 - binary_crossentropy: 0.4099 - val_loss: 1.7106 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7735\n",
      "Epoch 119/500\n",
      "182/182 [==============================] - 17s 96ms/step - loss: 1.3197 - accuracy: 0.7363 - binary_crossentropy: 0.3826 - val_loss: 1.7387 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.8017\n",
      "Epoch 120/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3132 - accuracy: 0.7527 - binary_crossentropy: 0.3763 - val_loss: 1.7359 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7990\n",
      "Epoch 121/500\n",
      "182/182 [==============================] - 17s 96ms/step - loss: 1.3177 - accuracy: 0.7308 - binary_crossentropy: 0.3809 - val_loss: 1.7355 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.7988\n",
      "Epoch 122/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3185 - accuracy: 0.7418 - binary_crossentropy: 0.3819 - val_loss: 1.7233 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.7867\n",
      "Epoch 123/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3336 - accuracy: 0.7308 - binary_crossentropy: 0.3971 - val_loss: 1.7232 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.7868\n",
      "Epoch 124/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3140 - accuracy: 0.7747 - binary_crossentropy: 0.3777 - val_loss: 1.7323 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.7961\n",
      "Epoch 125/500\n",
      "182/182 [==============================] - 17s 96ms/step - loss: 1.3134 - accuracy: 0.7802 - binary_crossentropy: 0.3772 - val_loss: 1.7380 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.8019\n",
      "Epoch 126/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3352 - accuracy: 0.6978 - binary_crossentropy: 0.3992 - val_loss: 1.7393 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.8034\n",
      "Epoch 127/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3270 - accuracy: 0.7473 - binary_crossentropy: 0.3911 - val_loss: 1.7411 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.8053\n",
      "Epoch 128/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3264 - accuracy: 0.7198 - binary_crossentropy: 0.3907 - val_loss: 1.7391 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.8034\n",
      "Epoch 129/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3333 - accuracy: 0.7473 - binary_crossentropy: 0.3977 - val_loss: 1.7562 - val_accuracy: 0.5870 - val_binary_crossentropy: 0.8207\n",
      "Epoch 130/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3228 - accuracy: 0.7363 - binary_crossentropy: 0.3874 - val_loss: 1.7817 - val_accuracy: 0.4783 - val_binary_crossentropy: 0.8464\n",
      "Epoch 131/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3249 - accuracy: 0.7198 - binary_crossentropy: 0.3896 - val_loss: 1.7734 - val_accuracy: 0.4565 - val_binary_crossentropy: 0.8383\n",
      "Epoch 132/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3350 - accuracy: 0.7308 - binary_crossentropy: 0.3999 - val_loss: 1.7686 - val_accuracy: 0.4783 - val_binary_crossentropy: 0.8336\n",
      "Epoch 133/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3038 - accuracy: 0.7473 - binary_crossentropy: 0.3689 - val_loss: 1.7618 - val_accuracy: 0.5652 - val_binary_crossentropy: 0.8269\n",
      "Epoch 134/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3317 - accuracy: 0.7033 - binary_crossentropy: 0.3969 - val_loss: 1.7709 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.8361\n",
      "Epoch 135/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3329 - accuracy: 0.6703 - binary_crossentropy: 0.3983 - val_loss: 1.7954 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.8608\n",
      "Epoch 136/500\n",
      "182/182 [==============================] - 17s 96ms/step - loss: 1.3185 - accuracy: 0.7253 - binary_crossentropy: 0.3840 - val_loss: 1.8097 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.8753\n",
      "Epoch 137/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3284 - accuracy: 0.6978 - binary_crossentropy: 0.3941 - val_loss: 1.8060 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.8718\n",
      "Epoch 138/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3240 - accuracy: 0.7418 - binary_crossentropy: 0.3898 - val_loss: 1.7802 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.8462\n",
      "Epoch 139/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3263 - accuracy: 0.7088 - binary_crossentropy: 0.3923 - val_loss: 1.7920 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.8581\n",
      "Epoch 140/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3188 - accuracy: 0.7363 - binary_crossentropy: 0.3849 - val_loss: 1.8111 - val_accuracy: 0.4565 - val_binary_crossentropy: 0.8773\n",
      "Epoch 141/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3265 - accuracy: 0.7143 - binary_crossentropy: 0.3928 - val_loss: 1.7827 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.8491\n",
      "Epoch 142/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3338 - accuracy: 0.7363 - binary_crossentropy: 0.4002 - val_loss: 1.7881 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.8546\n",
      "Epoch 143/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3417 - accuracy: 0.7253 - binary_crossentropy: 0.4083 - val_loss: 1.8112 - val_accuracy: 0.4783 - val_binary_crossentropy: 0.8779\n",
      "Epoch 144/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3452 - accuracy: 0.7473 - binary_crossentropy: 0.4120 - val_loss: 1.8555 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9224\n",
      "Epoch 145/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3289 - accuracy: 0.6978 - binary_crossentropy: 0.3959 - val_loss: 1.8969 - val_accuracy: 0.4783 - val_binary_crossentropy: 0.9640\n",
      "Epoch 146/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3267 - accuracy: 0.7143 - binary_crossentropy: 0.3938 - val_loss: 1.8359 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.9030\n",
      "Epoch 147/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3396 - accuracy: 0.7253 - binary_crossentropy: 0.4068 - val_loss: 1.8224 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.8898\n",
      "Epoch 148/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3143 - accuracy: 0.7418 - binary_crossentropy: 0.3817 - val_loss: 1.8171 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.8846\n",
      "Epoch 149/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3324 - accuracy: 0.6868 - binary_crossentropy: 0.4000 - val_loss: 1.8489 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.9166\n",
      "Epoch 150/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3264 - accuracy: 0.6923 - binary_crossentropy: 0.3942 - val_loss: 1.8466 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.9144\n",
      "Epoch 151/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3173 - accuracy: 0.7637 - binary_crossentropy: 0.3852 - val_loss: 1.8306 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.8986\n",
      "Epoch 152/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3178 - accuracy: 0.7363 - binary_crossentropy: 0.3858 - val_loss: 1.8004 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.8686\n",
      "Epoch 153/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3054 - accuracy: 0.7747 - binary_crossentropy: 0.3736 - val_loss: 1.7987 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.8670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3292 - accuracy: 0.7033 - binary_crossentropy: 0.3976 - val_loss: 1.8158 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.8843\n",
      "Epoch 155/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3366 - accuracy: 0.7582 - binary_crossentropy: 0.4052 - val_loss: 1.8649 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.9335\n",
      "Epoch 156/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3417 - accuracy: 0.7418 - binary_crossentropy: 0.4104 - val_loss: 1.9095 - val_accuracy: 0.4783 - val_binary_crossentropy: 0.9783\n",
      "Epoch 157/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3423 - accuracy: 0.7802 - binary_crossentropy: 0.4112 - val_loss: 1.9049 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9739\n",
      "Epoch 158/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3198 - accuracy: 0.7198 - binary_crossentropy: 0.3888 - val_loss: 1.8095 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.8786\n",
      "Epoch 159/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3147 - accuracy: 0.7308 - binary_crossentropy: 0.3839 - val_loss: 1.7990 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.8683\n",
      "Epoch 160/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3268 - accuracy: 0.7143 - binary_crossentropy: 0.3962 - val_loss: 1.8035 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.8729\n",
      "Epoch 161/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3099 - accuracy: 0.7637 - binary_crossentropy: 0.3794 - val_loss: 1.8057 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.8753\n",
      "Epoch 162/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3135 - accuracy: 0.7527 - binary_crossentropy: 0.3831 - val_loss: 1.8116 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.8813\n",
      "Epoch 163/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3296 - accuracy: 0.7308 - binary_crossentropy: 0.3994 - val_loss: 1.8005 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.8704\n",
      "Epoch 164/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3294 - accuracy: 0.7308 - binary_crossentropy: 0.3994 - val_loss: 1.7948 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.8649\n",
      "Epoch 165/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3186 - accuracy: 0.7418 - binary_crossentropy: 0.3888 - val_loss: 1.8015 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.8718\n",
      "Epoch 166/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3356 - accuracy: 0.7253 - binary_crossentropy: 0.4060 - val_loss: 1.8163 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.8867\n",
      "Epoch 167/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3290 - accuracy: 0.6978 - binary_crossentropy: 0.3995 - val_loss: 1.8137 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.8843\n",
      "Epoch 168/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3143 - accuracy: 0.7308 - binary_crossentropy: 0.3849 - val_loss: 1.8083 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.8791\n",
      "Epoch 169/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3078 - accuracy: 0.7418 - binary_crossentropy: 0.3786 - val_loss: 1.8130 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.8839\n",
      "Epoch 170/500\n",
      "182/182 [==============================] - 17s 96ms/step - loss: 1.3158 - accuracy: 0.7198 - binary_crossentropy: 0.3868 - val_loss: 1.8169 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.8880\n",
      "Epoch 171/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3113 - accuracy: 0.7363 - binary_crossentropy: 0.3825 - val_loss: 1.8196 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.8908\n",
      "Epoch 172/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3117 - accuracy: 0.7253 - binary_crossentropy: 0.3831 - val_loss: 1.8270 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.8984\n",
      "Epoch 173/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3217 - accuracy: 0.7363 - binary_crossentropy: 0.3932 - val_loss: 1.8069 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.8785\n",
      "Epoch 174/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3369 - accuracy: 0.6978 - binary_crossentropy: 0.4086 - val_loss: 1.8069 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.8787\n",
      "Epoch 175/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3015 - accuracy: 0.7747 - binary_crossentropy: 0.3734 - val_loss: 1.8040 - val_accuracy: 0.4783 - val_binary_crossentropy: 0.8759\n",
      "Epoch 176/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3245 - accuracy: 0.7363 - binary_crossentropy: 0.3965 - val_loss: 1.7933 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.8654\n",
      "Epoch 177/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3289 - accuracy: 0.7418 - binary_crossentropy: 0.4011 - val_loss: 1.8076 - val_accuracy: 0.4783 - val_binary_crossentropy: 0.8799\n",
      "Epoch 178/500\n",
      "182/182 [==============================] - 18s 96ms/step - loss: 1.3101 - accuracy: 0.7473 - binary_crossentropy: 0.3825 - val_loss: 1.8431 - val_accuracy: 0.5870 - val_binary_crossentropy: 0.9155\n",
      "Epoch 179/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3035 - accuracy: 0.7418 - binary_crossentropy: 0.3760 - val_loss: 1.8511 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9237\n",
      "Epoch 180/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.2973 - accuracy: 0.7308 - binary_crossentropy: 0.3700 - val_loss: 1.8395 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9123\n",
      "Epoch 181/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3033 - accuracy: 0.7582 - binary_crossentropy: 0.3762 - val_loss: 1.8194 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.8924\n",
      "Epoch 182/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3329 - accuracy: 0.6593 - binary_crossentropy: 0.4060 - val_loss: 1.8110 - val_accuracy: 0.4783 - val_binary_crossentropy: 0.8842\n",
      "Epoch 183/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3111 - accuracy: 0.7637 - binary_crossentropy: 0.3843 - val_loss: 1.8001 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.8734\n",
      "Epoch 184/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.2933 - accuracy: 0.7637 - binary_crossentropy: 0.3668 - val_loss: 1.8038 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.8774\n",
      "Epoch 185/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3160 - accuracy: 0.7527 - binary_crossentropy: 0.3896 - val_loss: 1.8356 - val_accuracy: 0.4783 - val_binary_crossentropy: 0.9093\n",
      "Epoch 186/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3048 - accuracy: 0.7418 - binary_crossentropy: 0.3786 - val_loss: 1.8566 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9304\n",
      "Epoch 187/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3151 - accuracy: 0.7253 - binary_crossentropy: 0.3891 - val_loss: 1.8668 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9409\n",
      "Epoch 188/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3244 - accuracy: 0.7143 - binary_crossentropy: 0.3985 - val_loss: 1.8778 - val_accuracy: 0.4565 - val_binary_crossentropy: 0.9521\n",
      "Epoch 189/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3123 - accuracy: 0.7473 - binary_crossentropy: 0.3867 - val_loss: 1.9009 - val_accuracy: 0.4783 - val_binary_crossentropy: 0.9753\n",
      "Epoch 190/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3245 - accuracy: 0.7143 - binary_crossentropy: 0.3990 - val_loss: 1.8324 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.9070\n",
      "Epoch 191/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3033 - accuracy: 0.7363 - binary_crossentropy: 0.3780 - val_loss: 1.8127 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.8875\n",
      "Epoch 192/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.2999 - accuracy: 0.7253 - binary_crossentropy: 0.3748 - val_loss: 1.8080 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.8830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3103 - accuracy: 0.7198 - binary_crossentropy: 0.3854 - val_loss: 1.8077 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.8829\n",
      "Epoch 194/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.2965 - accuracy: 0.7802 - binary_crossentropy: 0.3717 - val_loss: 1.8179 - val_accuracy: 0.5870 - val_binary_crossentropy: 0.8932\n",
      "Epoch 195/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.2845 - accuracy: 0.7527 - binary_crossentropy: 0.3599 - val_loss: 1.8249 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9004\n",
      "Epoch 196/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3085 - accuracy: 0.7308 - binary_crossentropy: 0.3841 - val_loss: 1.8300 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9057\n",
      "Epoch 197/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3022 - accuracy: 0.7582 - binary_crossentropy: 0.3780 - val_loss: 1.8508 - val_accuracy: 0.4783 - val_binary_crossentropy: 0.9267\n",
      "Epoch 198/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.2996 - accuracy: 0.7747 - binary_crossentropy: 0.3756 - val_loss: 1.8562 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9323\n",
      "Epoch 199/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.2996 - accuracy: 0.7308 - binary_crossentropy: 0.3758 - val_loss: 1.8685 - val_accuracy: 0.4783 - val_binary_crossentropy: 0.9448\n",
      "Epoch 200/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.2965 - accuracy: 0.7527 - binary_crossentropy: 0.3729 - val_loss: 1.8929 - val_accuracy: 0.4565 - val_binary_crossentropy: 0.9693\n",
      "Epoch 201/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3001 - accuracy: 0.7473 - binary_crossentropy: 0.3766 - val_loss: 1.8820 - val_accuracy: 0.4565 - val_binary_crossentropy: 0.9587\n",
      "Epoch 202/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3048 - accuracy: 0.7143 - binary_crossentropy: 0.3816 - val_loss: 1.8644 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9413\n",
      "Epoch 203/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3164 - accuracy: 0.6978 - binary_crossentropy: 0.3933 - val_loss: 1.8592 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9362\n",
      "Epoch 204/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.2936 - accuracy: 0.7527 - binary_crossentropy: 0.3707 - val_loss: 1.8639 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9412\n",
      "Epoch 205/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3093 - accuracy: 0.7143 - binary_crossentropy: 0.3866 - val_loss: 1.8459 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9234\n",
      "Epoch 206/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3124 - accuracy: 0.6868 - binary_crossentropy: 0.3900 - val_loss: 1.8584 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.9360\n",
      "Epoch 207/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3546 - accuracy: 0.6868 - binary_crossentropy: 0.4323 - val_loss: 1.8566 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9344\n",
      "Epoch 208/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3345 - accuracy: 0.7033 - binary_crossentropy: 0.4123 - val_loss: 1.9507 - val_accuracy: 0.5000 - val_binary_crossentropy: 1.0286\n",
      "Epoch 209/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3203 - accuracy: 0.7033 - binary_crossentropy: 0.3983 - val_loss: 2.0098 - val_accuracy: 0.5000 - val_binary_crossentropy: 1.0879\n",
      "Epoch 210/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3016 - accuracy: 0.7418 - binary_crossentropy: 0.3798 - val_loss: 1.9350 - val_accuracy: 0.5000 - val_binary_crossentropy: 1.0133\n",
      "Epoch 211/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3349 - accuracy: 0.6813 - binary_crossentropy: 0.4133 - val_loss: 1.9697 - val_accuracy: 0.4783 - val_binary_crossentropy: 1.0482\n",
      "Epoch 212/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3119 - accuracy: 0.7253 - binary_crossentropy: 0.3905 - val_loss: 2.0703 - val_accuracy: 0.5870 - val_binary_crossentropy: 1.1490\n",
      "Epoch 213/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.2995 - accuracy: 0.7363 - binary_crossentropy: 0.3783 - val_loss: 2.0472 - val_accuracy: 0.5000 - val_binary_crossentropy: 1.1260\n",
      "Epoch 214/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.2865 - accuracy: 0.7582 - binary_crossentropy: 0.3654 - val_loss: 1.9173 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.9963\n",
      "Epoch 215/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3114 - accuracy: 0.7088 - binary_crossentropy: 0.3905 - val_loss: 1.8714 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9506\n",
      "Epoch 216/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3203 - accuracy: 0.7363 - binary_crossentropy: 0.3996 - val_loss: 1.8655 - val_accuracy: 0.4783 - val_binary_crossentropy: 0.9449\n",
      "Epoch 217/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3171 - accuracy: 0.7308 - binary_crossentropy: 0.3966 - val_loss: 1.8666 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9462\n",
      "Epoch 218/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.2936 - accuracy: 0.7418 - binary_crossentropy: 0.3733 - val_loss: 1.8756 - val_accuracy: 0.4783 - val_binary_crossentropy: 0.9554\n",
      "Epoch 219/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3008 - accuracy: 0.7857 - binary_crossentropy: 0.3807 - val_loss: 1.8887 - val_accuracy: 0.4783 - val_binary_crossentropy: 0.9687\n",
      "Epoch 220/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3163 - accuracy: 0.7033 - binary_crossentropy: 0.3964 - val_loss: 1.8981 - val_accuracy: 0.4565 - val_binary_crossentropy: 0.9783\n",
      "Epoch 221/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.2992 - accuracy: 0.7363 - binary_crossentropy: 0.3795 - val_loss: 1.8975 - val_accuracy: 0.4565 - val_binary_crossentropy: 0.9779\n",
      "Epoch 222/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3043 - accuracy: 0.7527 - binary_crossentropy: 0.3848 - val_loss: 1.8887 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9693\n",
      "Epoch 223/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.2956 - accuracy: 0.7143 - binary_crossentropy: 0.3763 - val_loss: 1.8899 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9707\n",
      "Epoch 224/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.2854 - accuracy: 0.7473 - binary_crossentropy: 0.3662 - val_loss: 1.8828 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.9638\n",
      "Epoch 225/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.2987 - accuracy: 0.7473 - binary_crossentropy: 0.3797 - val_loss: 1.9060 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9872\n",
      "Epoch 226/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3000 - accuracy: 0.7363 - binary_crossentropy: 0.3812 - val_loss: 1.9313 - val_accuracy: 0.5217 - val_binary_crossentropy: 1.0126\n",
      "Epoch 227/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.2949 - accuracy: 0.7418 - binary_crossentropy: 0.3764 - val_loss: 1.9359 - val_accuracy: 0.5000 - val_binary_crossentropy: 1.0175\n",
      "Epoch 228/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.2958 - accuracy: 0.7527 - binary_crossentropy: 0.3774 - val_loss: 1.9196 - val_accuracy: 0.5000 - val_binary_crossentropy: 1.0013\n",
      "Epoch 229/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.2987 - accuracy: 0.7308 - binary_crossentropy: 0.3805 - val_loss: 1.9418 - val_accuracy: 0.5000 - val_binary_crossentropy: 1.0237\n",
      "Epoch 230/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.2820 - accuracy: 0.7802 - binary_crossentropy: 0.3640 - val_loss: 1.9506 - val_accuracy: 0.4783 - val_binary_crossentropy: 1.0328\n",
      "Epoch 231/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3021 - accuracy: 0.7143 - binary_crossentropy: 0.3843 - val_loss: 1.9559 - val_accuracy: 0.4783 - val_binary_crossentropy: 1.0383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.2940 - accuracy: 0.7418 - binary_crossentropy: 0.3764 - val_loss: 1.9137 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9962\n",
      "Epoch 233/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.2988 - accuracy: 0.7418 - binary_crossentropy: 0.3814 - val_loss: 1.8929 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9756\n",
      "Epoch 234/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.2940 - accuracy: 0.7198 - binary_crossentropy: 0.3768 - val_loss: 1.8735 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.9564\n",
      "Epoch 235/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.2899 - accuracy: 0.7418 - binary_crossentropy: 0.3729 - val_loss: 1.8680 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.9512\n",
      "Epoch 236/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.2979 - accuracy: 0.7527 - binary_crossentropy: 0.3811 - val_loss: 1.8991 - val_accuracy: 0.4783 - val_binary_crossentropy: 0.9825\n",
      "Epoch 237/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.2854 - accuracy: 0.7637 - binary_crossentropy: 0.3688 - val_loss: 1.9247 - val_accuracy: 0.4783 - val_binary_crossentropy: 1.0082\n",
      "Epoch 238/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3049 - accuracy: 0.7143 - binary_crossentropy: 0.3886 - val_loss: 1.9373 - val_accuracy: 0.4565 - val_binary_crossentropy: 1.0210\n",
      "Epoch 239/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.2810 - accuracy: 0.7473 - binary_crossentropy: 0.3648 - val_loss: 1.9390 - val_accuracy: 0.4565 - val_binary_crossentropy: 1.0230\n",
      "Epoch 240/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3024 - accuracy: 0.7253 - binary_crossentropy: 0.3864 - val_loss: 1.9270 - val_accuracy: 0.4565 - val_binary_crossentropy: 1.0112\n",
      "Epoch 241/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3107 - accuracy: 0.7033 - binary_crossentropy: 0.3949 - val_loss: 1.8866 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9709\n",
      "Epoch 242/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.2902 - accuracy: 0.7418 - binary_crossentropy: 0.3747 - val_loss: 1.8502 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.9348\n",
      "Epoch 243/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.2896 - accuracy: 0.7363 - binary_crossentropy: 0.3743 - val_loss: 1.8459 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.9307\n",
      "Epoch 244/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3033 - accuracy: 0.6978 - binary_crossentropy: 0.3881 - val_loss: 1.8464 - val_accuracy: 0.5435 - val_binary_crossentropy: 0.9314\n",
      "Epoch 245/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.2909 - accuracy: 0.7363 - binary_crossentropy: 0.3760 - val_loss: 1.8462 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.9314\n",
      "Epoch 246/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.2888 - accuracy: 0.7143 - binary_crossentropy: 0.3741 - val_loss: 1.8388 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.9242\n",
      "Epoch 247/500\n",
      "182/182 [==============================] - 17s 96ms/step - loss: 1.2969 - accuracy: 0.7198 - binary_crossentropy: 0.3825 - val_loss: 1.8312 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.9168\n",
      "Epoch 248/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.2894 - accuracy: 0.7582 - binary_crossentropy: 0.3751 - val_loss: 1.8392 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9251\n",
      "Epoch 249/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.2788 - accuracy: 0.7527 - binary_crossentropy: 0.3648 - val_loss: 1.8474 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9335\n",
      "Epoch 250/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.2845 - accuracy: 0.7473 - binary_crossentropy: 0.3707 - val_loss: 1.8495 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9358\n",
      "Epoch 251/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3085 - accuracy: 0.7363 - binary_crossentropy: 0.3949 - val_loss: 1.8573 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9438\n",
      "Epoch 252/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.2721 - accuracy: 0.7802 - binary_crossentropy: 0.3587 - val_loss: 1.8612 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9479\n",
      "Epoch 253/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3275 - accuracy: 0.7527 - binary_crossentropy: 0.4143 - val_loss: 1.8388 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.9258\n",
      "Epoch 254/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.2941 - accuracy: 0.7308 - binary_crossentropy: 0.3811 - val_loss: 1.8246 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.9117\n",
      "Epoch 255/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.2872 - accuracy: 0.7637 - binary_crossentropy: 0.3745 - val_loss: 1.8218 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.9091\n",
      "Epoch 256/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.2780 - accuracy: 0.7253 - binary_crossentropy: 0.3655 - val_loss: 1.8200 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.9076\n",
      "Epoch 257/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.2826 - accuracy: 0.7363 - binary_crossentropy: 0.3703 - val_loss: 1.8196 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.9074\n",
      "Epoch 258/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.2896 - accuracy: 0.7198 - binary_crossentropy: 0.3775 - val_loss: 1.8206 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.9086\n",
      "Epoch 259/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.2784 - accuracy: 0.7802 - binary_crossentropy: 0.3666 - val_loss: 1.8140 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.9023\n",
      "Epoch 260/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.2923 - accuracy: 0.7308 - binary_crossentropy: 0.3806 - val_loss: 1.8158 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.9042\n",
      "Epoch 261/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.2864 - accuracy: 0.7637 - binary_crossentropy: 0.3750 - val_loss: 1.8163 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.9050\n",
      "Epoch 262/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.2927 - accuracy: 0.7198 - binary_crossentropy: 0.3815 - val_loss: 1.8206 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9095\n",
      "Epoch 263/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.2883 - accuracy: 0.7088 - binary_crossentropy: 0.3773 - val_loss: 1.8270 - val_accuracy: 0.4783 - val_binary_crossentropy: 0.9161\n",
      "Epoch 264/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.3661 - accuracy: 0.7198 - binary_crossentropy: 0.4553 - val_loss: 1.8319 - val_accuracy: 0.4783 - val_binary_crossentropy: 0.9213\n",
      "Epoch 265/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.2854 - accuracy: 0.7527 - binary_crossentropy: 0.3748 - val_loss: 1.8490 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9385\n",
      "Epoch 266/500\n",
      "182/182 [==============================] - 17s 95ms/step - loss: 1.2825 - accuracy: 0.7363 - binary_crossentropy: 0.3722 - val_loss: 1.8371 - val_accuracy: 0.4565 - val_binary_crossentropy: 0.9268\n",
      "Epoch 267/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.3013 - accuracy: 0.7418 - binary_crossentropy: 0.3911 - val_loss: 1.8323 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9223\n",
      "Epoch 268/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.3016 - accuracy: 0.7582 - binary_crossentropy: 0.3917 - val_loss: 1.8119 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9021\n",
      "Epoch 269/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.2875 - accuracy: 0.7143 - binary_crossentropy: 0.3778 - val_loss: 1.8025 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.8929\n",
      "Epoch 270/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.2962 - accuracy: 0.7198 - binary_crossentropy: 0.3867 - val_loss: 1.8512 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271/500\n",
      "182/182 [==============================] - 17s 96ms/step - loss: 1.2851 - accuracy: 0.7253 - binary_crossentropy: 0.3759 - val_loss: 1.9216 - val_accuracy: 0.4783 - val_binary_crossentropy: 1.0125\n",
      "Epoch 272/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.2826 - accuracy: 0.7692 - binary_crossentropy: 0.3735 - val_loss: 1.9389 - val_accuracy: 0.4783 - val_binary_crossentropy: 1.0299\n",
      "Epoch 273/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.2992 - accuracy: 0.7473 - binary_crossentropy: 0.3904 - val_loss: 1.8782 - val_accuracy: 0.5217 - val_binary_crossentropy: 0.9695\n",
      "Epoch 274/500\n",
      "182/182 [==============================] - 17s 94ms/step - loss: 1.2778 - accuracy: 0.7308 - binary_crossentropy: 0.3692 - val_loss: 1.8586 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9502\n",
      "Epoch 275/500\n",
      "182/182 [==============================] - 17s 93ms/step - loss: 1.2880 - accuracy: 0.7143 - binary_crossentropy: 0.3796 - val_loss: 1.8663 - val_accuracy: 0.5000 - val_binary_crossentropy: 0.9580\n",
      "Epoch 276/500\n",
      "112/182 [=================>............] - ETA: 5s - loss: 1.2581 - accuracy: 0.7500 - binary_crossentropy: 0.3499"
     ]
    }
   ],
   "source": [
    "'''Model fitting'''\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "# patient early stopping\n",
    "#es = EarlyStopping(monitor='accuracy', mode='max', patience=100)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=50)\n",
    "\n",
    "\n",
    "\n",
    "%time fit = model.fit(Input_matrix, labels, epochs=500,callbacks=[callback],validation_split=0.2, shuffle=True,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(Input_matrix, labels, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[0]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_T1_Solid_Surv.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_T1_Solid_Surv.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(40, 25))\n",
    "epoch = np.arange(202) + 1\n",
    "fontsize = 30\n",
    "plt.plot(epoch, fit.history['accuracy'], marker=\"o\", linewidth=2,\n",
    "         color=\"steelblue\", label=\"train\")\n",
    "plt.plot(epoch, fit.history['val_accuracy'], marker=\"o\", linewidth=2,\n",
    "         color=\"red\", label=\"test\")\n",
    "plt.plot(epoch, fit.history['loss'], marker=\"o\", linewidth=2,\n",
    "         color=\"orange\", label=\"loss\")\n",
    "plt.xlabel('Epoch', fontsize=fontsize)\n",
    "plt.ylabel('% Accuracy', fontsize=fontsize)\n",
    "plt.xticks(fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.legend(frameon=False, fontsize=30);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
