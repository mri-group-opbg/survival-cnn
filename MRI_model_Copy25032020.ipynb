{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "QEA9wlJn4s9A",
    "outputId": "27e40092-7320-48db-ae57-c84c8793943a"
   },
   "outputs": [],
   "source": [
    "# Modules to import\n",
    "\n",
    "!pip install --user nipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DA AGGIUNGERE NEL NUOVO CODICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22. 28.]\n",
      " [49. 64.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "with tf.device('/gpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user nilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4pP4i32fGX69"
   },
   "outputs": [],
   "source": [
    "# Main Imports\n",
    "\n",
    "import nilearn\n",
    "\n",
    "from nilearn.image import resample_to_img\n",
    "\n",
    "import pylab as plt\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nb\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import seaborn as sns #added\n",
    "sns.set(style=\"darkgrid\") #added\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ht-UHC0h6SMC"
   },
   "outputs": [],
   "source": [
    "# Local directory where the Drive is mounted\n",
    "rootDirectory = \"/data/RMN/LUCA_PASQUINI\"\n",
    "\n",
    "# Local subdirectory where dataset is mounted\n",
    "dataDir = \"DATI_SEGMENTATI_SCALATI_media\"\n",
    "\n",
    "# Dataset dir\n",
    "datasetDir = f\"{rootDirectory}/{dataDir}\"\n",
    "\n",
    "datasetDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A_Dvkvt1oLkC"
   },
   "outputs": [],
   "source": [
    "from nilearn.image import mean_img #added\n",
    "from nilearn.plotting import plot_anat #added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls {datasetDir}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survival Data\n",
    "\n",
    "In order to associate survival data we read a CSV file provided with 0/1 for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm {datasetDir}/Def_Labels.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm {datasetDir}/Def_Labels_array.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls {datasetDir}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thing=['Labels_array.csv*']\n",
    "#for name in glob.glob(f\"{datasetDir}/*\"):\n",
    "    #print(name)\n",
    " #   folders = os.path.basename(name)\n",
    "    #print(folders)\n",
    "  #  if thing in folders:\n",
    "#        folders.remove(thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls {datasetDir}/BIAVATI_S/ROI/SOLID.nii*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = \"/data/RMN/LUCA_PASQUINI/DATI_SEGMENTATI_SCALATI_media/Array_Labels_Def.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(fileName, sep=\";\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"Subject\", \"Survival\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('Subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump Survival data\n",
    "#print(df)\n",
    "\n",
    "pd.set_option('display.max_rows', len(df))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def normalize_name(subject_path, add_name=False):\n",
    "    #Components= []\n",
    "#    subject = os.path.basename(subject_path)\n",
    " #   subject = re.sub(r'^(DE|D|DI|LO|DEL)_', '', subject)\n",
    " #   components =  subject.split(\"_\")\n",
    "#    if len(components) > 1 and add_name:\n",
    " #       return components[0].title() + components[1][0]\n",
    " #   else:\n",
    " #       return components[0].title()\n",
    "\n",
    "#def get_subject_metadata(subject_path, subjects_with_name=[]):\n",
    "  #  dirname = os.path.basename(subject_path)\n",
    "  #  return (dirname, normalize_name(subject_path, add_name=dirname in subjects_with_name))\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_name(subject_path, add_name):\n",
    "    #Components= []\n",
    "    subject = os.path.basename(subject_path)\n",
    "    subject = re.sub(r'^(DE|D|DI|LO|DEL)_', '', subject)\n",
    "    components =  subject.split(\"_\")\n",
    "    if add_name[0]==components[0] or add_name[1]==components[0] or add_name[2]==components[0] :\n",
    "            return components[0].title() + components[1][0].capitalize()\n",
    "    else:\n",
    "            return components[0].title()\n",
    "        \n",
    "\n",
    "def get_subject_metadata(subject_path, subjects_with_name=[]):\n",
    "    dirname = os.path.basename(subject_path)\n",
    "    return (dirname, normalize_name(subject_path, add_name=[name for name in subjects_with_name]))\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subject=[\"EMANUELA_T\",\"LUCA_PASQUINI\",\"LUCA_L\",\"MICHELE_M\"]\n",
    "#Components= []\n",
    "#for i in range(len(subject)):\n",
    "#    components =  subject[i].split(\"_\")\n",
    "#    Components.append(components)\n",
    "#    \n",
    "#print(Components)\n",
    "#r=len(Components)\n",
    "#for i in range(r):\n",
    "#    for j in range(r):\n",
    "#        if j!=i:\n",
    "#            if Components[i][0]==Components[j][0]:\n",
    "#                name=Components[i][0].title() + Components[i][1][0].capitalize()\n",
    "#            else:\n",
    "#                name=Components[i][0].title()\n",
    "#                \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions application\n",
    "Subject_dirs=[]\n",
    "for subject_path in glob.glob(f\"{datasetDir}/*\"):\n",
    "    subjects_dirs=[get_subject_metadata(subject_path , subjects_with_name=[\"BIANCHI\",\"BOVE\",\"PROIETTI\"])]\n",
    "    #print(subjects_dirs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Df_Subjects_dirs = pd.DataFrame()\n",
    "for subject_path in glob.glob(f\"{datasetDir}/*\"):\n",
    "    subjects_dirs=[get_subject_metadata(subject_path , subjects_with_name=[\"BIANCHI\",\"BOVE\",\"PROIETTI\"])]\n",
    "    print(subjects_dirs)\n",
    "    df_subject_dirs = pd.DataFrame(subjects_dirs,columns=[\"Path\", \"Subject\"])\n",
    "    Df_Subjects_dirs=pd.concat([Df_Subjects_dirs,df_subject_dirs],ignore_index=True)\n",
    "\n",
    "pd.set_option('display.max_rows', len(Df_Subjects_dirs))\n",
    "print(Df_Subjects_dirs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subjects name must be normalized to encounter directory names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Df_Subjects_dirs = pd.DataFrame()\n",
    "#for i in range(len(Subjects_dirs)):\n",
    "#    df_subject_dirs = pd.DataFrame(Subjects_dirs[i],columns=[\"Path\", \"Subject\"])\n",
    "#    Df_Subjects_dirs=pd.concat([Df_Subjects_dirs,df_subject_dirs],ignore_index=True)\n",
    "        \n",
    "        \n",
    "              \n",
    "#pd.set_option('display.max_rows', len(Df_Subjects_dirs))\n",
    "#print(Df_Subjects_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Df_Subjects_dirs = Df_Subjects_dirs.set_index('Subject')\n",
    "pd.set_option('display.max_rows', len(Df_Subjects_dirs))\n",
    "\n",
    "print(Df_Subjects_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=Df_Subjects_dirs\n",
    "x.drop(index='Array', columns='Path')\n",
    "# Delete rows with index label a & b    \n",
    "modX= x.drop(['Pascal','Mitchell','Rufini','Farella','Array'])\n",
    "#modX[\"Path\"]\n",
    "pd.set_option('display.max_rows', len(modX))\n",
    "modX = pd.DataFrame(modX)\n",
    "print(modX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = modX.join(df, on='Subject')\n",
    "\n",
    "pd.set_option('display.max_rows', len(result))\n",
    "result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAN_index=result['Survival'].index[result['Survival'].apply(np.isnan)]\n",
    "\n",
    "df_index=result.index.values.tolist()\n",
    "int_index=[df_index.index(i) for i in NAN_index]\n",
    "int_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=[df.iloc[x]['Survival'] for x in int_index]\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in label:\n",
    "    result['Survival'].fillna(l,inplace=True)\n",
    "pd.set_option('display.max_rows', len(result))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''' Get index positions of value in dataframe i.e. dfObj.'''\n",
    "def getIndexes(dfObj, value):\n",
    "    listOfPos = list()\n",
    "    result = dfObj.isin([value]) # Get bool dataframe with True at positions where the given value exists\n",
    "    seriesObj = result.any() # Get list of columns that contains the value\n",
    "    columnNames = list(seriesObj[seriesObj == True].index)\n",
    "    for col in columnNames: # Iterate over list of columns and fetch the rows indexes where value exists\n",
    "        rows = list(result[col][result[col] == True].index)\n",
    "        for row in rows:\n",
    "            listOfPos.append((row, col))\n",
    "# Return a list of tuples indicating the positions of value in the dataframe\n",
    "    return listOfPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(modX)\n",
    "#print(df)\n",
    "\n",
    "#modX.shape\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfElems=[]\n",
    "Dim = []\n",
    "Data = []\n",
    "IMG=[]\n",
    "for Path in result[\"Path\"]:\n",
    "    #print(Path)\n",
    "    if os.path.isfile(f\"{datasetDir}/{Path}/T1_registered.nii.gz\"):\n",
    "\n",
    "        IMG_reg = nb.load(f\"{datasetDir}/{Path}/T1_registered.nii.gz\")\n",
    "        DATA= IMG_reg.get_data()\n",
    "        a = [DATA.shape]\n",
    "        Dim.append(a)\n",
    "        Data.append(DATA)\n",
    "        IMG.append(IMG_reg)\n",
    "        \n",
    "\n",
    "        IMG_roi = nb.load(f\"{datasetDir}/{Path}/ROI/SOLID.nii\")\n",
    "        ROI_DATA=IMG_roi.get_data()\n",
    "        b=[ROI_DATA.shape]\n",
    "        Dim.append(b)\n",
    "        Data.append(ROI_DATA)\n",
    "        IMG.append(IMG_roi)\n",
    "        \n",
    "        path=[f\"{Path}\"]\n",
    "        listOfElems.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(listOfElems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfElems=[]\n",
    "Dim = []\n",
    "Data = []\n",
    "IMG=[]\n",
    "for Path in result[\"Path\"]:\n",
    "    #print(Path)\n",
    "    if os.path.isfile(f\"{datasetDir}/{Path}/T1_registered.nii.gz\"):\n",
    "\n",
    "        IMG_reg = nb.load(f\"{datasetDir}/{Path}/T1_registered.nii.gz\")\n",
    "        DATA= IMG_reg.get_data()\n",
    "        a = [DATA.shape]\n",
    "        Dim.append(a)\n",
    "        Data.append(DATA)\n",
    "        IMG.append(IMG_reg)\n",
    "        \n",
    "\n",
    "        IMG_roi = nb.load(f\"{datasetDir}/{Path}/ROI/SOLID.nii\")\n",
    "        ROI_DATA=IMG_roi.get_data()\n",
    "        b=[ROI_DATA.shape]\n",
    "        Dim.append(b)\n",
    "        Data.append(ROI_DATA)\n",
    "        IMG.append(IMG_roi)\n",
    "        \n",
    "        path=[f\"{Path}\"]\n",
    "        listOfElems.append(path)\n",
    "        \n",
    "    else:\n",
    "        if os.path.isfile(f\"{datasetDir}/{Path}/T1.nii\"):\n",
    "            IMG_reg = nb.load(f\"{datasetDir}/{Path}/T1.nii\")\n",
    "            DATA= IMG_reg.get_data()\n",
    "            a = [DATA.shape]\n",
    "            Dim.append(a)\n",
    "            Data.append(DATA)\n",
    "            IMG.append(IMG_reg)\n",
    "            \n",
    "            IMG_roi = nb.load(f\"{datasetDir}/{Path}/ROI/SOLID.nii\")\n",
    "            ROI_DATA=IMG_roi.get_data()\n",
    "            b=[ROI_DATA.shape]\n",
    "            Dim.append(b)\n",
    "            Data.append(ROI_DATA)\n",
    "            IMG.append(IMG_roi)\n",
    "            \n",
    "            path=[f\"{Path}\"]\n",
    "            listOfElems.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(listOfElems)\n",
    "print(listOfElems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(listOfElems)\n",
    "listOfElems[6][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[\"Santis\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1_Subject=[]\n",
    "for i in range(len(listOfElems)):\n",
    "    Pos=getIndexes(result, listOfElems[i][0])\n",
    "    print(Pos[0][0])\n",
    "    T1_Subject.append(Pos[0][0])\n",
    "    \n",
    "T1_Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1_Subject_array=np.asarray(T1_Subject)\n",
    "#T1_Labels=[]\n",
    "for i in range(len(T1_Subject_array)):\n",
    "    try:\n",
    "        # Subject found\n",
    "        lab = df.loc[T1_Subject_array[i],\"Survival\"]\n",
    "        print(f\"Found {lab} for {T1_Subject_array[i]}\")\n",
    "    except:\n",
    "        # Subject not found\n",
    "        print(f\"Subject {T1_Subject_array[i]} not fount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1_Subject_array=np.asarray(T1_Subject)\n",
    "T1_Labels=[]\n",
    "for i in range(len(T1_Subject_array)):\n",
    "    #try:\n",
    "        # Subject found\n",
    "        lab = result.loc[T1_Subject_array[i],\"Survival\"]\n",
    "        T1_Labels.append(int(lab))\n",
    "        #print(f\"Found {lab} for {T1_Subject_array[i]}\")\n",
    "    #except:\n",
    "        # Subject not found\n",
    "        #print(f\"Subject {T1_Subject_array[i]} not fount\")\n",
    "        \n",
    "#T1_Labels=np.asarray(T1_Labels)\n",
    "#T1_Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label_Def=[]\n",
    "for x in range(len(T1_Labels)):\n",
    "    label_Def=[[T1_Labels[x]]*2]\n",
    "    Label_Def.append(label_Def)\n",
    "    \n",
    "Label_Def=np.asarray(Label_Def)\n",
    "Label_Def=np.ravel(Label_Def)\n",
    "Label_Def\n",
    "#label_array=np.array([Label_Def[1][0][0],Label_Def[1][0][1]])\n",
    "#label_array.shape\n",
    "#for i in range(len(Label_Def)):\n",
    "#    for j in range(2):\n",
    "#        array_label=np.array([Label_Def[i][0][j]])\n",
    "#print(array_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#listOfElems=['MARAGNO_CLARA','MAIOLINI_SANTA']\n",
    "#dictOfPos = {elem: getIndexes(result, elem[0]) for elem in listOfElems}\n",
    "#print(dictOfPos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dim=np.asarray(Dim)   \n",
    "Data=np.asarray(Data)\n",
    "IMG=np.asarray(IMG)\n",
    "\n",
    "IMG[:][:].shape\n",
    "print(Dim[219])\n",
    "Data[219].shape\n",
    "IMG[219].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results\n",
    "Data.shape\n",
    "IMG.shape\n",
    "#L.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "OPLIAbKFcbqU",
    "outputId": "e064400a-8866-43dd-a632-94bdb939945a"
   },
   "outputs": [],
   "source": [
    "#cerco i valori minimi sulla base dei quali fare il resample\n",
    "Min_value=np.amin(Dim, axis=1)\n",
    "Min_value\n",
    "Min=np.amin(Min_value, axis=0)\n",
    "Min\n",
    "Min_value.shape\n",
    "Min[2]\n",
    "# Min_value[:,0]\n",
    "# pos=np.where(Min_value[:,0]==Min[0])\n",
    "# pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# [p.append(q.index(v)) if v in q else p.append(99999) for v in vm]\n",
    "\n",
    "\n",
    "not_in_index = [x for x in range(Min_value.shape[0]) if not np.all(Min_value[x] == (192, 256, 144))]\n",
    "\n",
    "not_in_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_1=np.where(Min_value[:,0]==192)\n",
    "pos_1\n",
    "\n",
    "pos_2=np.where(Min_value[:,1]==256)\n",
    "pos_2\n",
    "\n",
    "pos_3=np.where(Min_value[:,2]==144)\n",
    "pos_3\n",
    "\n",
    "eq=np.intersect1d(pos_1,pos_2)\n",
    "eq\n",
    "\n",
    "index_IMG=np.intersect1d(eq,pos_3)\n",
    "index_IMG\n",
    "def_index=random.choice(index_IMG)\n",
    "print(def_index)\n",
    "\n",
    "index_IMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in not_in_index:\n",
    "    Res=nilearn.image.resample_to_img(IMG[i], IMG[def_index])\n",
    "    IMG[i]=Res\n",
    "    Data[i]=IMG[i].get_data()\n",
    "\n",
    "        \n",
    "#     Resample_results.append(Res_IMG)\n",
    "\n",
    "# Prova_Data=np.ndarray.tolist(Data)\n",
    "\n",
    "# for i in index_IMG:\n",
    "#     Resample_results.append(Prova_Data[i])\n",
    "\n",
    "# Resample_results=np.asarray(Resample_results)\n",
    "# Resample_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "VDkMnRGH94yM",
    "outputId": "51c1065c-e50a-4db7-c954-0a7372eb9394"
   },
   "outputs": [],
   "source": [
    "Input_matrix=np.empty((len(Data),192,256,144)) \n",
    "\n",
    "for i in not_in_index:\n",
    "\n",
    "    Input_matrix[i,:,:,:]=np.array(Data[i])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in index_IMG:\n",
    "\n",
    "    Input_matrix[i,:,:,:]=np.array(Data[i])\n",
    "    \n",
    "    \n",
    "    \n",
    "Input_matrix.shape\n",
    "\n",
    "# Input_matrix[20,47,10,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bY3XmLCcwzLJ"
   },
   "outputs": [],
   "source": [
    "#added block\n",
    "## Create list of indices and shuffle them\n",
    "N = Input_matrix.shape[0]\n",
    "indices = np.arange(N)\n",
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "asxqHJSCyLv7",
    "outputId": "cf5a9991-9999-4560-f650-e540d34d60a1"
   },
   "outputs": [],
   "source": [
    "#labels block added\n",
    "labels=Label_Def\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fDRFNqXt2Fjj"
   },
   "outputs": [],
   "source": [
    "#added block\n",
    "#  Cut the dataset at 80% to create the training and test set\n",
    "N_80p = int(0.8 * N)\n",
    "indices_train = indices[:N_80p]\n",
    "indices_test = indices[N_80p:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "GpslU81A2Xm5",
    "outputId": "7057859f-facf-44ff-8459-ad12774b6bba"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train = Input_matrix[indices_train, ...]\n",
    "X_test = Input_matrix[indices_test, ...]\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uoVH0H0L2mLi"
   },
   "outputs": [],
   "source": [
    "#outcome variable block added\n",
    "y_train = labels[indices_train]\n",
    "y_test = labels[indices_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#block added to create the model\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "4Wo6WG3a3Bcb",
    "outputId": "76f6a8be-5a08-4214-9cc8-4a44244b25b5"
   },
   "outputs": [],
   "source": [
    "#added block\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ZyrKnNa6hA0"
   },
   "outputs": [],
   "source": [
    "#block added to create the model\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "T1fNBc8I6kKz",
    "outputId": "1819255b-7496-4dfc-8632-5589c831d0d2"
   },
   "outputs": [],
   "source": [
    "# Get shape of input data\n",
    "data_shape = tuple(X_train.shape[1:])\n",
    "\n",
    "# Specify shape of convolution kernel\n",
    "kernel_size = (3, 3)\n",
    "\n",
    "# Specify number of output categories\n",
    "n_classes = 2\n",
    "\n",
    "# Specify number of filters per layer\n",
    "filters = 16\n",
    "\n",
    "data_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "colab_type": "code",
    "id": "9XWnJwve64vE",
    "outputId": "cd0d2aa4-da27-438c-cdb8-3da15ec8dff6"
   },
   "outputs": [],
   "source": [
    "#model block added\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters, kernel_size, activation='relu', input_shape=data_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(filters * 2, kernel_size, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(filters * 4, kernel_size, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# optimizer\n",
    "learning_rate = 1e-5\n",
    "adam = Adam(lr=learning_rate)\n",
    "sgd = SGD(lr=learning_rate)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam, # swap out for sgd \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3P4SBfIE7oB7"
   },
   "outputs": [],
   "source": [
    "#added block\n",
    "nEpochs = 100  # Increase this value for better results (i.e., more training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "euoUfFI87tQx"
   },
   "outputs": [],
   "source": [
    "batch_size = 16   # Increasing this value might speed up fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "acIp4UFS7vLO",
    "outputId": "03cb4be6-b276-4825-b001-8c4bacca82a9"
   },
   "outputs": [],
   "source": [
    "%time fit = model.fit(X_train, y_train, epochs=nEpochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "anF1eo5KBWL9",
    "outputId": "59966627-073f-49cb-8aa5-9559437be298"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 4))\n",
    "epoch = np.arange(nEpochs) + 1\n",
    "fontsize = 16\n",
    "plt.plot(epoch, fit.history['accuracy'], marker=\"o\", linewidth=2,\n",
    "         color=\"steelblue\", label=\"accuracy\")\n",
    "plt.plot(epoch, fit.history['loss'], marker=\"o\", linewidth=2,\n",
    "         color=\"orange\", label=\"loss\")\n",
    "plt.xlabel('epoch', fontsize=fontsize)\n",
    "plt.xticks(fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.legend(frameon=False, fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MRI_model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
