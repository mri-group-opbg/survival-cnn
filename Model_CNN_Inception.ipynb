{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Input\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "import keras\n",
    "\n",
    "input_img = Input(shape=(256, 256, 3))\n",
    "\n",
    "tower_1 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)\n",
    "tower_1 = Conv2D(64, (3, 3), padding='same', activation='relu')(tower_1)\n",
    "\n",
    "tower_2 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)\n",
    "tower_2 = Conv2D(64, (5, 5), padding='same', activation='relu')(tower_2)\n",
    "\n",
    "tower_3 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(input_img)\n",
    "tower_3 = Conv2D(64, (1, 1), padding='same', activation='relu')(tower_3)\n",
    "\n",
    "conv_output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denselayer_1 = Dense(512, activation='softmax')(conv_output)\n",
    "\n",
    "denselayer_2 = Dense(256, activation='softmax')(denselayer_1)\n",
    "\n",
    "output = Dense(2, activation='softmax')(denselayer_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=input_img, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(data, labels, epochs=10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Appunti vari:\n",
    "\n",
    "- Common choices for width and height image sizes inputted to Convolutional Neural Networks include 32x32 64x64 224x224 227x227 256x256. For some dataset you can simply ignore the aspect ratio and squish, distort, and compress your images prior to feeding them through your netwotk. On other datasets, it's advantageous to preprocess them further by resizing along the shortest dimension and then cropping the center (center crop).        \n",
    "nilearn.image.crop_img\n",
    "\n",
    "-the initial dataset need to be splitted into two parts: training set and test set (common split test are: 66.7%-33.3% or 75%-25% or 90%-10%). After the classifier has been trained, we can evaluate the performing on testing set.In order to IDENTIFY THE SET OF HYPERPARAMETERS THAT WORKS THE BEST, you should create a third data split called the validation set. This test is used as \"fake test data\", so we can tune our parameters.\n",
    "\n",
    "-Obtaining a high accuracy classifier is dependent on finding a set of weights W and b such that our data points are correctly classified. Instead of relying on pure randomness, we need to define an optimization algorithm that allows us to literally improve W and b.\n",
    "\n",
    "-the default WEIGHT INITIALIZATION method used in the Keras library in called \"Glorot initialization\" or \"Xavier initialization\" (pag.169)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
