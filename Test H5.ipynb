{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"mytestfile.hdf5\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"dataset-survivor-adc-224-100-perc.pickle\", \"rb\") as file:\n",
    "    a = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = np.array(list(a[0].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][\"ALESSANDRINI_GLAUCO\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Tue Dec 10 21:26:54 2019\n",
    "\n",
    "@author: Christopher J. Burke\n",
    "Give a worked example of saving a list of class objects with mixed\n",
    "storage types to a HDF5 file and reading in file back to a list of class\n",
    "objects.  The solution is inspired by this bug report\n",
    "https://github.com/h5py/h5py/issues/735\n",
    "and the numpy and hdf5 documentation\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "class test_object:\n",
    "    \"\"\" Define a storage class that keeps info that we want to record\n",
    "      for every object\n",
    "    \"\"\"\n",
    "    # explictly state the name, datatype and shape for every\n",
    "    #  class variable\n",
    "    #  The names MUST exactly match the class variable names in the __init__\n",
    "    store_names = ['a', 'b', 'c', 'd', 'e']\n",
    "    store_types = ['i8', 'i4', 'f8', 'S80', 'f8']\n",
    "    store_shapes = [None, None, None, None, [4]]\n",
    "    # Make the tuples that will define the numpy structured array\n",
    "    # https://docs.scipy.org/doc/numpy/user/basics.rec.html\n",
    "    sz = len(store_names)\n",
    "    store_def_tuples = []\n",
    "    for i in range(sz):\n",
    "        if store_shapes[i] is not None:\n",
    "            store_def_tuples.append((store_names[i], store_types[i], store_shapes[i]))\n",
    "        else:\n",
    "            store_def_tuples.append((store_names[i], store_types[i]))\n",
    "    # Actually define the numpy structured/compound data type\n",
    "    store_struct_numpy_dtype = np.dtype(store_def_tuples)\n",
    "\n",
    "    def __init__(self):\n",
    "        self.a = 0\n",
    "        self.b = 0\n",
    "        self.c = 0.0\n",
    "        self.d = '0'\n",
    "        self.e = [0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "    def store_objlist_as_hd5f(self, objlist, fileName):\n",
    "        \"\"\"Function to save the class structure into hdf5\n",
    "        objlist -  is a list of the test_objects\n",
    "        fileName - is the h5 filename for output\n",
    "        \"\"\"        \n",
    "        # First create the array of numpy structered arrays\n",
    "        np_dset = np.ndarray(len(objlist), dtype=self.store_struct_numpy_dtype)\n",
    "        # Convert the class variables into the numpy structured dtype\n",
    "        for i, curobj in enumerate(objlist):\n",
    "            for j in range(len(self.store_names)):\n",
    "                np_dset[i][self.store_names[j]] = getattr(curobj, self.store_names[j])\n",
    "        # Data set should be all loaded ready to write out\n",
    "        fp = h5py.File(fileName, 'w')\n",
    "        hf_dset = fp.create_dataset('dset', shape=(len(objlist),), dtype=self.store_struct_numpy_dtype)\n",
    "        hf_dset[:] = np_dset\n",
    "        fp.close()\n",
    "\n",
    "    def fill_objlist_from_hd5f(self, fileName):\n",
    "        \"\"\" Function to read in the hdf5 file created by store_objlist_as_hdf5\n",
    "          and store the contents into a list of test_objects\n",
    "          fileName - si the h5 filename for input\n",
    "         \"\"\"\n",
    "        fp = h5py.File(fileName, 'r')\n",
    "        np_dset = np.array(fp['dset'])\n",
    "        # Start with empty list\n",
    "        all_objs = []\n",
    "        # iterate through the numpy structured array and save to objects\n",
    "        for i in range(len(np_dset)):\n",
    "            tmp = test_object()\n",
    "            for j in range(len(self.store_names)):\n",
    "                setattr(tmp, self.store_names[j], np_dset[i][self.store_names[j]])\n",
    "            # Append object to list\n",
    "            all_objs.append(tmp)\n",
    "        return all_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't convert element 0 ([[[0.26442087]\n  [0.26442087]\n  [0.27778531]\n  ...\n  [0.26324136]\n  [0.        ]\n  [0.        ]]\n\n [[0.26442087]\n  [0.26442087]\n  [0.27778531]\n  ...\n  [0.26324136]\n  [0.        ]\n  [0.        ]]\n\n [[0.26221271]\n  [0.26221271]\n  [0.27252585]\n  ...\n  [0.27647004]\n  [0.        ]\n  [0.        ]]\n\n ...\n\n [[0.        ]\n  [0.        ]\n  [0.        ]\n  ...\n  [0.        ]\n  [0.        ]\n  [0.        ]]\n\n [[0.        ]\n  [0.        ]\n  [0.        ]\n  ...\n  [0.        ]\n  [0.        ]\n  [0.        ]]\n\n [[0.        ]\n  [0.        ]\n  [0.        ]\n  ...\n  [0.        ]\n  [0.        ]\n  [0.        ]]]) to hsize_t",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32mh5py/utils.pyx\u001b[0m in \u001b[0;36mh5py.utils.convert_tuple\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-f0ae32e42318>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubject\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubjects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ALESSANDRINI_GLAUCO\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mdsid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_new_dset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0mdset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36mmake_new_dset\u001b[0;34m(parent, shape, dtype, data, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0msid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNULL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0msid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5s.pyx\u001b[0m in \u001b[0;36mh5py.h5s.create_simple\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/utils.pyx\u001b[0m in \u001b[0;36mh5py.utils.convert_tuple\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't convert element 0 ([[[0.26442087]\n  [0.26442087]\n  [0.27778531]\n  ...\n  [0.26324136]\n  [0.        ]\n  [0.        ]]\n\n [[0.26442087]\n  [0.26442087]\n  [0.27778531]\n  ...\n  [0.26324136]\n  [0.        ]\n  [0.        ]]\n\n [[0.26221271]\n  [0.26221271]\n  [0.27252585]\n  ...\n  [0.27647004]\n  [0.        ]\n  [0.        ]]\n\n ...\n\n [[0.        ]\n  [0.        ]\n  [0.        ]\n  ...\n  [0.        ]\n  [0.        ]\n  [0.        ]]\n\n [[0.        ]\n  [0.        ]\n  [0.        ]\n  ...\n  [0.        ]\n  [0.        ]\n  [0.        ]]\n\n [[0.        ]\n  [0.        ]\n  [0.        ]\n  ...\n  [0.        ]\n  [0.        ]\n  [0.        ]]]) to hsize_t"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for subject in subjects:\n",
    "    dset = f.create_dataset(subject, a[0][subject], dtype=a[0][\"ALESSANDRINI_GLAUCO\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
